---
title: "Lab7 addendum"
output: github_document
---


  
### Econ B2000, MA Econometrics
### Kevin R Foster, the Colin Powell School at the City College of New York, CUNY
### Fall 2023

OK I already effed up the ordering by splitting Part 3 into 2 sub-parts. Now I'm going to further break Part2 into a main part and an addendum. 

This is some complicated coding to make later coding less complicated. It's an investment.

We want just 2 simple things: to standarize our data (all X-variables to have values just in [0,1] interval) and to split the data into a training set (that we use to estimate the model) and a test set (that we use to evaluate how well the model performs on new data that it hasn't trained on).

But depending on your model, doing just those 2 simple things can take a bit of work. Best to do that in the privacy of your own home.

I'll show this for a simple set of X-variables. Your version will be more complicated. The ones that are already nice dummy variables are easy and this coding might seem overly elaborate for them. But bigger factors such as the PUMA get ugly fast.

I'm not necessarily saying you should use PUMA in your regression, only that if you want to use a big factor with many levels, this is a way to do it. Each PUMA number codes a 'neighborhood' -- although the size of that neighborhood is trying to enclose a roughly equal number of people. Dense areas in NYC get small geographic areas but upstate, where people are sparse, the PUMAs can be large geographic areas. FYI, 4-digit codes starting with 37 are Bronx, 38 Manhattan, 39 SI, 40 Brooklyn and 41 Queens. You can find the codes if you'd like. But here I'll just leave the code number.


```{r eval = FALSE}

# fix each variable you want in your regression
# this example is for small version, 
# public_work_num ~ female + educ_hs + educ_somecoll + educ_college + educ_advdeg + AGE + PUMA_factor

# I want to demonstrate how to work with more complicated factors so I will also include PUMA
dat_use$PUMA_factor <- as.factor(dat_use$PUMA)

d_pub_work <- data.frame(model.matrix(~ dat_use$public_work_num)) 

d_female <- data.frame(model.matrix(~ dat_use$female))
d_educ_hs <- data.frame(model.matrix(~ dat_use$educ_hs))
d_educ_somecoll <- data.frame(model.matrix(~ dat_use$educ_somecoll))
d_educ_college <- data.frame(model.matrix(~ dat_use$educ_college))
d_educ_advdeg <- data.frame(model.matrix(~ dat_use$educ_advdeg))
d_age <- data.frame(model.matrix(~ dat_use$AGE))
d_PUMA <- data.frame(model.matrix(~ dat_use$PUMA_factor)) # which is really big!

```

In this step (and later) I worry that I don't want to accidentally create factors that are empty. Depending on your subgroup that you choose, this might happen. That will cause problems for later estimation (the math tries to answer the question, how are the zero observations in some group different from the other groups?). So we want to catch the problem early. Run colSums() to verify.

```{r eval = FALSE}
sum( colSums(d_PUMA) == 0) # should be zero
```
Then this puts them all together,
```{r eval=FALSE}

# there are better ways to code this, but this should be more robust to your other choices

dat_for_analysis_sub <- data.frame(
  d_pub_work[,2], # need [] since model.matrix includes intercept term
  d_female[,2],
  d_educ_hs[,2],
  d_educ_somecoll[,2],
  d_educ_college[,2],
  d_educ_advdeg[,2],
  d_age[,2],
  d_PUMA[,2:145] ) # this last term is why model.matrix 


# this is just about me being anal-retentive, see difference in names(dat_for_analysis_sub) before and after running this bit
names(dat_for_analysis_sub)
names(dat_for_analysis_sub) <- sub("dat_use.","",names(dat_for_analysis_sub)) # drops each repetition of dat_use

names(dat_for_analysis_sub)[1] <- "pub_work"
names(dat_for_analysis_sub)[2] <- "female"
names(dat_for_analysis_sub)[3:6] <- c("HS","SomeColl","College","AdvDeg")
names(dat_for_analysis_sub)[7] <- "Age"

names(dat_for_analysis_sub)

```

Then to create training data and test data,
```{r eval=FALSE}

require("standardize")
set.seed(654321)
NN <- length(dat_for_analysis_sub$pub_work)

restrict_1 <- (runif(NN) < 0.1) # use 10% as training data, ordinarily this would be much bigger but start small
summary(restrict_1)
dat_train <- subset(dat_for_analysis_sub, restrict_1)
dat_test <- subset(dat_for_analysis_sub, !restrict_1)

# again check this below, should be zero
sum( colSums(dat_train) == 0)

```

Now writing the formula is a bit of a pain. Would like to have 'pub_work ~ female + HS + SomeColl + COllege + AdvDeg + Age + PUMA' but that last term is no longer an easy factor but a mess of 144 dummies! Don't copy-paste 144 times, instead:

```{r eval=FALSE}
fmla_sobj <- reformulate( names(dat_for_analysis_sub[2:151]), response = "pub_work")

sobj <- standardize(fmla_sobj, dat_train, family = binomial)

s_dat_test <- predict(sobj, dat_test)

```

Now your OLS and logit models can be run like this:

```{r eval=FALSE}

model_lpm1 <- lm(sobj$formula, data = sobj$data)
summary(model_lpm1)
pred_vals_lpm <- predict(model_lpm1, s_dat_test)
pred_model_lpm1 <- (pred_vals_lpm > mean(pred_vals_lpm))
table(pred = pred_model_lpm1, true = dat_test$pub_work)

# logit 
model_logit1 <- glm(sobj$formula, family = binomial, data = sobj$data)
summary(model_logit1)
pred_vals <- predict(model_logit1, s_dat_test, type = "response")
pred_model_logit1 <- (pred_vals > 0.5)
table(pred = pred_model_logit1, true = dat_test$pub_work)

```



